{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a521b6-4d28-4921-b2ec-2465e6f46ca5",
   "metadata": {},
   "source": [
    "# Домашнее задание № 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6073c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import skimage\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "# from PCV.geometry import homography\n",
    "# from PCV.localdescriptors import sift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30cf95-80f0-432d-9053-4cb9776992ee",
   "metadata": {},
   "source": [
    "# Поиск объектов в видеопотоке "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a5193-25dc-4df2-91b1-77860dac156f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Задача - придумать и реализовать алгоритм поиска (обнаружения без классификации) движущихся объектов.\n",
    "\n",
    "В качестве исходных данных приведена выборка с видеофайлами и аннотацией для каждого кадра файла. Аннотация задана в виде ограничивающих прямоугольников в формате ```(y1,x1,y2,x2)```, где\n",
    "- ```(x1,y1)``` - верхний левый угол прямоугольника;\n",
    "- ```(x2,y2)``` - нижний правый угол прямоугольника.\n",
    "\n",
    "Ссылка на данные – https://disk.yandex.ru/d/RdjMDoQQO8Ngcw\n",
    "\n",
    "В качестве обучающей можно брать любые видеофайлы. При этом должны быть отдельно выбраны тестовые данные, которые не будут использованы в создании решения. \n",
    "\n",
    "Видеофайл с результатами работы алгоритма должен быть прикреплен вместе с решением. Пример фрагмента видеофайла с результатом поиска объектов приведен ниже.\n",
    "\n",
    "Исходный код может быть в формате ```.py``` или ```.ipynb```.\n",
    "\n",
    "![annotation](annot_example.gif \"annotation\")\n",
    "\n",
    "## Требования к результату\n",
    "- поиск должен находить геометрические место объекта на видеоизображении. Геометрическое место задано ограничивающим прямоугольником (bounding box);\n",
    "- продолжительность решения для любого одного видеофайла не должна превышать 10 минут;\n",
    "- должна быть приведена оценка точности решения;\n",
    "- привести демонстрацию результатов требется на одном из тестовых видеофайлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9407eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video(save_dir, size, img_format='jpg', vido_format='avi'):\n",
    "    out_name = Path(save_dir).parts[-1]\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(Path(save_dir) / Path(f'{out_name}.{vido_format}')),\n",
    "                          fourcc, 20, tuple(size.astype(int)))\n",
    "\n",
    "    for fname in tqdm(sorted(map(str, Path(save_dir).glob(f'*.{img_format}')))):\n",
    "        imag = skimage.io.imread(fname)\n",
    "        imag = cv2.cvtColor(imag, cv2.COLOR_RGB2BGR)\n",
    "        out.write(imag)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d92a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video(num=-1,path='./tmp/', sleep=0):\n",
    "    cap = get_video(num if num >=0 else 0, path=path)\n",
    "    get_video_details(cap)\n",
    "    cv2.startWindowThread()\n",
    "    while (cap.isOpened()):\n",
    "        is_ok, frame = cap.read()\n",
    "        if not is_ok:\n",
    "            break\n",
    "            \n",
    "        if sleep > 0:\n",
    "            time.sleep(sleep)\n",
    "\n",
    "        cv2.imshow(\"sparse optical flow\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7177b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_points(image):\n",
    "    \"\"\"\n",
    "    Функция для поиска особых точек и получения их дескрипторов \n",
    "    \"\"\"\n",
    "    \n",
    "    hyp_params = dict(\n",
    "        nfeatures = 200,\n",
    "        nOctaveLayers = 10,\n",
    "        contrastThreshold = 0.01,\n",
    "        edgeThreshold = 6,\n",
    "        sigma = 2.0)  # hyp params\n",
    "    detector = cv2.SIFT_create(**hyp_params)\n",
    "\n",
    "    keypoints, desc = detector.detectAndCompute(image.copy(), None)\n",
    "    return keypoints, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f280442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyp_and_d(first, second):\n",
    "    FLANN_INDEX_KDTREE = 2\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    ratio_thresh = 0.5\n",
    "    keypoints1, desc1 = spec_points(first)\n",
    "    keypoints2, desc2 = spec_points(second)\n",
    "    \n",
    "    matches = flann.knnMatch(desc1, desc2, k=2)\n",
    "    \n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good_matches.append(m)\n",
    "    \n",
    "    return keypoints1, keypoints2, good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f6e815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_M(first, second):\n",
    "    h, w = first.shape\n",
    "    \n",
    "    \n",
    "    keypoints1, keypoints2, good_matches = get_keyp_and_d(first, second)\n",
    "    \n",
    "    pts1 = []\n",
    "    pts2 = []   \n",
    "    \n",
    "    for good_matche in good_matches:\n",
    "        pts1.append(keypoints1[good_matche.queryIdx].pt)\n",
    "        pts2.append(keypoints2[good_matche.trainIdx].pt)\n",
    "    \n",
    "    pts1 = np.array(pts1).astype(np.float32)\n",
    "    pts2 = np.array(pts2).astype(np.float32)\n",
    "    \n",
    "#     print('pts1', pts1)\n",
    "#     print('pts2', pts2)\n",
    "    \n",
    "    model = RANSACRegressor()\n",
    "    model.fit(pts1, pts2)\n",
    "\n",
    "    points1 = np.array([[0,0], [h,0], [0,w], [h,w]]).astype(np.float32)\n",
    "    points2 = model.predict(points1).astype(np.float32)\n",
    "    M = cv2.getPerspectiveTransform(points1, points2)\n",
    "    return M\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20dcc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory(cap, max_idx=-1):\n",
    "    cnt, w, h, fps = get_video_details(cap)\n",
    "    cnt = int(cnt)\n",
    "    color = (0, 255, 0)\n",
    "    feature_params = dict(maxCorners=300, qualityLevel=0.2, minDistance=2, blockSize=7)\n",
    "    lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    \n",
    "    is_ok, first_frame = cap.read()\n",
    "    if not is_ok:\n",
    "        print(\"ERR: Can't read\")\n",
    "        return\n",
    "#     plt.imshow(first_frame)\n",
    "#     plt.show()\n",
    "    \n",
    "    prev_gray = cv2.cvtColor(first_frame.copy(), cv2.COLOR_BGR2GRAY)\n",
    "#     prev = cv2.goodFeaturesToTrack(prev_gray, mask=None, **feature_params)\n",
    "    mask = np.zeros_like(first_frame)\n",
    "    idx = 0\n",
    "    for idx in tqdm(range(cnt-1)):\n",
    "        if not cap.isOpened():\n",
    "            break\n",
    "#         print(\"idx\", idx)\n",
    "        if max_idx > 0 and idx > max_idx:\n",
    "            break\n",
    "        is_ok, frame = cap.read()\n",
    "#         if not is_ok or idx == 10:\n",
    "#             break\n",
    "        if not is_ok:\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame.copy(), cv2.COLOR_BGR2GRAY)\n",
    "        mask = np.zeros_like(frame)\n",
    "        \n",
    "#         print('prob:', np.sum((prev_gray - gray)**2))\n",
    "        M = get_M(prev_gray.copy(), gray.copy())\n",
    "#         if np.sum(np.abs(M - np.array([[0, 0, 0], [0, 0, 0], [0, 0, 1]]))) < 0.1:\n",
    "#             print('bad M')\n",
    "#             break\n",
    "#         print('M',M)\n",
    "        trans_prev_gray = cv2.warpPerspective(prev_gray.copy(), M, (prev_gray.shape[1], prev_gray.shape[0]))\n",
    "        \n",
    "#         plt.imshow(trans_prev_gray, cmap='gray')\n",
    "#         plt.show()\n",
    "\n",
    "        prev = cv2.goodFeaturesToTrack(trans_prev_gray, mask=None, **feature_params)\n",
    "    \n",
    "        trans_gray = gray*(trans_prev_gray!=0).astype(np.uint8)\n",
    "        nextp, status, error = cv2.calcOpticalFlowPyrLK(prev_gray, trans_gray, prev, None, **lk_params)\n",
    "\n",
    "        good_old = prev[status == 1].astype(int)\n",
    "        good_new = nextp[status == 1].astype(int)\n",
    "\n",
    "        # Draws the optical flow tracks\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            mask = cv2.line(mask, (a, b), (c, d), color, 2)\n",
    "            frame = cv2.circle(frame, (a, b), 3, color, -1)\n",
    "\n",
    "        output = cv2.add(frame, mask)\n",
    "        prev_gray = gray.copy()\n",
    "        # Updates previous good feature points\n",
    "        prev = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "        cv2.imwrite(f'tmp/frame_{str(idx).zfill(4)}.jpg', output)\n",
    "#         idx += 1\n",
    "        \n",
    "        # Opens a new window and displays the output frame\n",
    "#         cv2.imshow(\"sparse optical flow\", output)\n",
    "        \n",
    "#         idx += 1\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "    # The following frees up resources and closes all windows\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf1bc522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clip_1.mov', 'Clip_10.mov', 'Clip_11.mov', 'Clip_2.mov', 'Clip_3.mov', 'Clip_37.mov', 'Clip_4.mov', 'Clip_5.mov', 'Clip_6.mov', 'Clip_7.mov', 'Clip_8.mov', 'Clip_9.mov']\n",
      "./Videos/Videos/Clip_10.mov\n",
      "1800.0 1920.0 1080.0 29.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08038dfc162b40a481cb881a8150f1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b37f32412b4a02b2029ea33e901300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cap = get_video(1)\n",
    "get_trajectory(cap)\n",
    "create_video('tmp', size=np.array((1920.0 , 1080.0)), vido_format='mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "281fbe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tmp.mp4']\n",
      "./tmp/tmp.mp4\n",
      "1799.0 1920.0 1080.0 20.0\n"
     ]
    }
   ],
   "source": [
    "show_video(sleep=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "583b0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(cap):\n",
    "    cnt = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    print(cnt, w, h, fps)\n",
    "    return cnt, w, h, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be76a7f8-b6e7-4fcf-9799-c4a0b0d9f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video(num, path='./Videos/Videos/'):\n",
    "    \"\"\"\n",
    "    Функция достающая видео\n",
    "    num - номер видео (если num == -1, то достаются все видео)\n",
    "    \n",
    "    \"\"\"\n",
    "    all_names = os.listdir(path)\n",
    "    names = []\n",
    "    for name in all_names:\n",
    "        if name.endswith(\".mov\") or name.endswith(\".mp4\"):\n",
    "            names.append(name)\n",
    "    print(names)\n",
    "    if num >= 0:\n",
    "        name_vid = names[num]\n",
    "        print(path+name_vid)\n",
    "        return cv2.VideoCapture(path+name_vid)\n",
    "    \n",
    "    videos = []\n",
    "    for name_vid in names:\n",
    "        videos.append(cv2.VideoCapture(path+name_vid))\n",
    "    return videos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ef74c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clip_1.mov', 'Clip_10.mov', 'Clip_11.mov', 'Clip_2.mov', 'Clip_3.mov', 'Clip_37.mov', 'Clip_4.mov', 'Clip_5.mov', 'Clip_6.mov', 'Clip_7.mov', 'Clip_8.mov', 'Clip_9.mov']\n",
      "./Videos/Videos/Clip_1.mov\n",
      "309.0 1920.0 1080.0 29.97\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mshow_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Videos/Videos/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [4], line 11\u001b[0m, in \u001b[0;36mshow_video\u001b[1;34m(num, path, sleep)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sleep \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse optical flow\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "show_video(0, './Videos/Videos/', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d6a5be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tmp.mp4']\n",
      "./tmp/tmp.mp4\n",
      "308.0 1920.0 1080.0 20.0\n"
     ]
    }
   ],
   "source": [
    "show_video(sleep=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4c50162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9609830a510c4c098de131866e0232d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/308 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tmp.mov']\n",
      "./tmp/tmp.mov\n",
      "308.0 1920.0 1080.0 20.0\n"
     ]
    }
   ],
   "source": [
    "create_video('tmp', size=np.array((1920.0 , 1080.0)), vido_format='mov')\n",
    "show_video(sleep=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f1ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
