{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a521b6-4d28-4921-b2ec-2465e6f46ca5",
   "metadata": {},
   "source": [
    "# Домашнее задание № 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6073c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import skimage\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "# from PCV.geometry import homography\n",
    "# from PCV.localdescriptors import sift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30cf95-80f0-432d-9053-4cb9776992ee",
   "metadata": {},
   "source": [
    "# Поиск объектов в видеопотоке "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a5193-25dc-4df2-91b1-77860dac156f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Задача - придумать и реализовать алгоритм поиска (обнаружения без классификации) движущихся объектов.\n",
    "\n",
    "В качестве исходных данных приведена выборка с видеофайлами и аннотацией для каждого кадра файла. Аннотация задана в виде ограничивающих прямоугольников в формате ```(y1,x1,y2,x2)```, где\n",
    "- ```(x1,y1)``` - верхний левый угол прямоугольника;\n",
    "- ```(x2,y2)``` - нижний правый угол прямоугольника.\n",
    "\n",
    "Ссылка на данные – https://disk.yandex.ru/d/RdjMDoQQO8Ngcw\n",
    "\n",
    "В качестве обучающей можно брать любые видеофайлы. При этом должны быть отдельно выбраны тестовые данные, которые не будут использованы в создании решения. \n",
    "\n",
    "Видеофайл с результатами работы алгоритма должен быть прикреплен вместе с решением. Пример фрагмента видеофайла с результатом поиска объектов приведен ниже.\n",
    "\n",
    "Исходный код может быть в формате ```.py``` или ```.ipynb```.\n",
    "\n",
    "![annotation](annot_example.gif \"annotation\")\n",
    "\n",
    "## Требования к результату\n",
    "- поиск должен находить геометрические место объекта на видеоизображении. Геометрическое место задано ограничивающим прямоугольником (bounding box);\n",
    "- продолжительность решения для любого одного видеофайла не должна превышать 10 минут;\n",
    "- должна быть приведена оценка точности решения;\n",
    "- привести демонстрацию результатов требется на одном из тестовых видеофайлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b465e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вспомогательная функция\n",
    "def plot_one_image(src_image, is_gray=False):\n",
    "    \"\"\"\n",
    "    Отрисовать с помощью plt исходное изображение.\n",
    "    \n",
    "    :param src_image: np.ndarray: исходное изображение\n",
    "    :param is_gray: bool: флаг для отображения ЧБ изображений\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    fig, m_axs = plt.subplots(1, 1, figsize=(6*2, 4*2), constrained_layout=True)\n",
    "    ax1 = m_axs\n",
    "\n",
    "    cmap = 'gray' if is_gray else None\n",
    "    ax1.set_title('Исходное изображение')\n",
    "    ax1.imshow(src_image, cmap=cmap)\n",
    "    ax1.set_xticks([]), ax1.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b08cfa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform_point(M, point):\n",
    "    v = np.array([[point[0]], [point[1]], [1]])\n",
    "    trans = M@v\n",
    "    new_x = np.sum(trans[0])/np.sum(trans[2])\n",
    "    new_y = np.sum(trans[1])/np.sum(trans[2])\n",
    "    return np.array([new_x, new_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "6fa17c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectory:\n",
    "    def __init__(self, idx):\n",
    "        self.points = []\n",
    "        self.d = 0\n",
    "        self.idx = idx\n",
    "    \n",
    "    def add_point(self, point):\n",
    "        self.points.append(np.array(point))\n",
    "    \n",
    "    def get_last(self):\n",
    "        return self.points[-1]\n",
    "    \n",
    "    def set_last(self, point):\n",
    "        self.d += np.sum(np.abs(point-self.points[-1]))\n",
    "        self.points[-1] = np.array(point)\n",
    "    \n",
    "    def get_trajectory_len(self):\n",
    "        return len(self.points)\n",
    "    \n",
    "    def add_d(self, d):\n",
    "        self.d += d\n",
    "        \n",
    "    def get_d(self):\n",
    "        return self.d\n",
    "    \n",
    "    def get_point(self, idx):\n",
    "        if idx < self.idx or self.idx+self.get_trajectory_len()-1 < idx:\n",
    "            return np.array([-1,-1])\n",
    "        return self.points[idx-self.idx]\n",
    "    \n",
    "#     def continue_trajectory(self, model):\n",
    "#         self.points.append(model.predict([self.points[-1]])[0])\n",
    "#         if len(self.points) > 1:\n",
    "#             self.points.append(model.predict([self.points[-1]])[0] + self.points[-1]-self.points[-2])\n",
    "#         else:\n",
    "#             self.points.append(model.predict([self.points[-1]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "12fcd691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trajectories:\n",
    "    def __init__(self):\n",
    "        self.trajectories = []\n",
    "        self.save_trajectories = []\n",
    "#     def add_trajectories(self, points):\n",
    "#         last_points = np.array([trajectory.get_last() for trajectory in self.trajectories])\n",
    "#         for point in points:\n",
    "#             point = point[0]\n",
    "#             if len(last_points) == 0 or np.min(np.abs(last_points[:,0] - point[0])) + \\\n",
    "#                                         np.min(np.abs(last_points[:,1] - point[1])) > 10:\n",
    "#                 self.trajectories.append(Trajectory())\n",
    "#                 self.trajectories[-1].add_point(point)\n",
    "        \n",
    "        \n",
    "    def update_trajectories(self, M, w, h):\n",
    "        bad_ind = []\n",
    "        for i, trajectory in enumerate(self.trajectories):\n",
    "            new_point = get_transform_point(M, trajectory.get_last())\n",
    "#             print(new_point)\n",
    "            if new_point[0] < w and new_point[0] > 0 and new_point[1] < h and new_point[1] > 0:\n",
    "                trajectory.add_point(np.uint32(new_point))\n",
    "            else:\n",
    "                bad_ind.append(i)\n",
    "        \n",
    "        for i in reversed(bad_ind):\n",
    "            del self.trajectories[i]\n",
    "            \n",
    "        \n",
    "    def get_last_points(self):\n",
    "        return np.float32([np.array([trajectory.get_last()]) for trajectory in self.trajectories])\n",
    "    \n",
    "    \n",
    "    def continue_trajectories(self, new_points, old_points, idx):\n",
    "#         i = 0\n",
    "\n",
    "        last_points = np.array([trajectory.get_last() for trajectory in self.trajectories])\n",
    "        if len(last_points) == 0:\n",
    "            for point in new_points:\n",
    "                self.trajectories.append(Trajectory(idx))\n",
    "                self.trajectories[-1].add_point(point)\n",
    "                return\n",
    "            \n",
    "        count_trajectories = len(self.trajectories)\n",
    "        temp_ind = list(range(count_trajectories))\n",
    "        \n",
    "        calc_ind = []\n",
    "        for i, point in enumerate(old_points):\n",
    "            if len(last_points) == 0:\n",
    "                self.trajectories.append(Trajectory(idx))\n",
    "                self.trajectories[-1].add_point(new_points[i])\n",
    "                continue\n",
    "                \n",
    "#             print(len(last_points), len(temp_ind))\n",
    "            dists = np.abs(last_points[:,0] - point[0]) + np.abs(last_points[:,1] - point[1])\n",
    "            ind = np.argmin(dists)\n",
    "            if dists[ind] < 20:\n",
    "                self.trajectories[temp_ind[ind]].add_point(new_points[i])\n",
    "                self.trajectories[temp_ind[ind]].add_d(dists[ind])\n",
    "                calc_ind.append(temp_ind[ind])\n",
    "                last_points = np.delete(last_points, ind, axis=0)\n",
    "                temp_ind.pop(ind)\n",
    "            else:\n",
    "                self.trajectories.append(Trajectory(idx))\n",
    "                self.trajectories[-1].add_point(new_points[i])\n",
    "           \n",
    "        print('cmp len', count_trajectories, len(calc_ind))\n",
    "        calc_ind = set(calc_ind)\n",
    "        all_ind = set(range(count_trajectories))\n",
    "        del_ind = list(set(a) ^ set(b))\n",
    "        del_ind = sorted(del_ind, reverse=True)\n",
    "        for ind in del_ind:\n",
    "            self.save_trajectories.append(self.trajectories[ind])\n",
    "            self.trajectories.pop(ind)\n",
    "    \n",
    "    def get_trajectories_len(self):\n",
    "        return np.array([trajectory.get_trajectory_len() for trajectory in self.trajectories])\n",
    "    \n",
    "    def get_trajectories_dist(self):\n",
    "        return np.array([trajectory.get_d() for trajectory in self.trajectories])\n",
    "          \n",
    "    def get_points(self, idx):\n",
    "        return np.array([trajectory.get_point(idx) for trajectory in self.trajectories])\n",
    "    \n",
    "    def load_all_trajectories(self):\n",
    "        self.trajectories = self.trajectories + self.save_trajectories\n",
    "        \n",
    "    def get_trajectories(self):\n",
    "        return self.trajectories\n",
    "    \n",
    "#         for trajectory in self.trajectories:\n",
    "#             if np.sum(np.abs(trajectory.get_last() - old_points[i])) < 10:\n",
    "#                 if np.sum(np.abs(trajectory.get_last() - new_points[i])) > 6: \n",
    "#                     trajectory.set_last(new_points[i])\n",
    "#                 i += 1\n",
    "#                 if i > len(old_points[i]):\n",
    "#                     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "9407eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video(save_dir, size, img_format='jpg', vido_format='avi'):\n",
    "    out_name = Path(save_dir).parts[-1]\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(str(Path(save_dir) / Path(f'{out_name}.{vido_format}')),\n",
    "                          fourcc, 20, tuple(size.astype(int)))\n",
    "\n",
    "    for fname in tqdm(sorted(map(str, Path(save_dir).glob(f'*.{img_format}')))):\n",
    "        imag = skimage.io.imread(fname)\n",
    "        imag = cv2.cvtColor(imag, cv2.COLOR_RGB2BGR)\n",
    "        out.write(imag)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "a0d92a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_video(num=-1,path='./tmp/', sleep=0):\n",
    "    cap = get_video(num if num >=0 else 0, path=path)\n",
    "    get_video_details(cap)\n",
    "    cv2.startWindowThread()\n",
    "    while (cap.isOpened()):\n",
    "        is_ok, frame = cap.read()\n",
    "        if not is_ok:\n",
    "            break\n",
    "            \n",
    "        if sleep > 0:\n",
    "            time.sleep(sleep)\n",
    "\n",
    "        cv2.imshow(\"sparse optical flow\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "7177b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_points(image):\n",
    "    \"\"\"\n",
    "    Функция для поиска особых точек и получения их дескрипторов \n",
    "    \"\"\"\n",
    "    \n",
    "    hyp_params = dict(\n",
    "        nfeatures = 250,\n",
    "        nOctaveLayers = 10,\n",
    "        contrastThreshold = 0.005,\n",
    "        edgeThreshold = 6,\n",
    "        sigma = 2.0)  # hyp params\n",
    "    detector = cv2.SIFT_create(**hyp_params)\n",
    "\n",
    "    keypoints, desc = detector.detectAndCompute(image.copy(), None)\n",
    "    return keypoints, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "2f280442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyp_and_d(first, second):\n",
    "    FLANN_INDEX_KDTREE = 2\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    ratio_thresh = 0.55\n",
    "    keypoints1, desc1 = spec_points(first)\n",
    "    keypoints2, desc2 = spec_points(second)\n",
    "    \n",
    "    matches = flann.knnMatch(desc1, desc2, k=2)\n",
    "    \n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good_matches.append(m)\n",
    "    \n",
    "    return keypoints1, keypoints2, good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "3f6e815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_M(first, second):\n",
    "    h, w = first.shape\n",
    "    \n",
    "    \n",
    "    keypoints1, keypoints2, good_matches = get_keyp_and_d(first, second)\n",
    "    \n",
    "    pts1 = []\n",
    "    pts2 = []   \n",
    "    \n",
    "    for good_matche in good_matches:\n",
    "        pts1.append(keypoints1[good_matche.queryIdx].pt)\n",
    "        pts2.append(keypoints2[good_matche.trainIdx].pt)\n",
    "    \n",
    "    pts1 = np.array(pts1).astype(np.float32)\n",
    "    pts2 = np.array(pts2).astype(np.float32)\n",
    "    \n",
    "#     print('pts1', pts1)\n",
    "#     print('pts2', pts2)\n",
    "    \n",
    "    model = RANSACRegressor()\n",
    "    model.fit(pts1, pts2)\n",
    "\n",
    "    points1 = np.array([[0,0], [0,h], [w,0], [w,h]]).astype(np.float32)\n",
    "    points2 = model.predict(points1).astype(np.float32)\n",
    "    M = cv2.getPerspectiveTransform(points1, points2)\n",
    "    return M, model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "27f2f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_zero_points(image):\n",
    "    p = np.where(image > 5)\n",
    "    y = p[0]\n",
    "    x = p[1]\n",
    "    all_points = np.array(list(zip(x, y)))\n",
    "    \n",
    "    points = np.array([all_points[0]])\n",
    "    \n",
    "    for point in all_points:\n",
    "        if np.min(np.abs(points[:,0] - point[0]) + np.abs(points[:,1] - point[1])) > 5:\n",
    "            points = np.r_[points, [point]]\n",
    "    points = np.array([[np.float32(point)] for point in points])\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "510e573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_stick(list_trajectories, w, h):\n",
    "    good_trajectories = []\n",
    "    for trajectory in list_trajectories:\n",
    "        points = np.array(trajectory.points)\n",
    "        if np.any(points[:, 0] > w//4) or np.any(points[:, 1] < h//3):\n",
    "            good_trajectories.append(trajectory)\n",
    "            \n",
    "    return good_trajectories  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "b7907db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_trajectories(list_image, trajectories):\n",
    "    trajectories.load_all_trajectories()\n",
    "    color = (0, 255, 0)\n",
    "    tr_lens = trajectories.get_trajectories_len()\n",
    "    tr_dist = trajectories.get_trajectories_dist()\n",
    "    inds = (np.where((tr_lens > 10) & (tr_dist/tr_lens > 3))[0]).tolist()\n",
    "    good_trajectories = [trajectory for i, trajectory in enumerate(trajectories.get_trajectories()) if i in inds]\n",
    "    \n",
    "    h, w, _ = list_image[0].shape\n",
    "    good_trajectories = del_stick(good_trajectories, w, h)\n",
    "    \n",
    "    for idx in tqdm(range(len(list_image))):\n",
    "        image = list_image[idx]\n",
    "        points = np.array([trajectory.get_point(idx) for trajectory in good_trajectories])\n",
    "        points = points[points[:,0] != -1]\n",
    "        output = image.copy()\n",
    "        for point in points:\n",
    "            output = cv2.circle(output, (point[0], point[1]), 3, color, -1)\n",
    "        cv2.imwrite(f'tmp2/frame_{str(idx).zfill(4)}.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "280c7cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bdb877356f47678bf6b2cec2e5a144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_trajectories(list_frames, trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "20dcc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory(cap, max_idx=-1, create_vid=True):\n",
    "    cnt, w, h, fps = get_video_details(cap)\n",
    "    cnt = int(cnt)\n",
    "    color = (0, 255, 0)\n",
    "    feature_params = dict(maxCorners=1000, qualityLevel=0.02, minDistance=2, blockSize=7)\n",
    "    lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    \n",
    "    is_ok, first_frame = cap.read()\n",
    "    if not is_ok:\n",
    "        print(\"ERR: Can't read\")\n",
    "        return\n",
    "    \n",
    "    prev_gray = cv2.cvtColor(first_frame.copy(), cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.zeros_like(first_frame)\n",
    "    idx = 0\n",
    "    trajectories = Trajectories()\n",
    "    list_frames = []\n",
    "    for idx in tqdm(range(cnt-1)):\n",
    "        if not cap.isOpened():\n",
    "            break\n",
    "#         print(\"idx\", idx)\n",
    "        if max_idx > 0 and idx > max_idx:\n",
    "            break\n",
    "        is_ok, frame = cap.read()\n",
    "        if not is_ok:\n",
    "            break\n",
    "        \n",
    "        list_frames.append(frame.copy())\n",
    "        gray = cv2.cvtColor(frame.copy(), cv2.COLOR_BGR2GRAY)\n",
    "        mask = np.zeros_like(frame)\n",
    "        \n",
    "        M, model = get_M(prev_gray.copy(), gray.copy())\n",
    "        trans_prev_gray = cv2.warpPerspective(prev_gray.copy(), M, (prev_gray.shape[1], prev_gray.shape[0]))\n",
    "        \n",
    "#         prev = cv2.goodFeaturesToTrack(trans_prev_gray, mask=None, **feature_params)\n",
    "        \n",
    "        trans_gray = gray*(trans_prev_gray!=0).astype(np.uint8)\n",
    "        nice_pic = np.abs(trans_prev_gray.astype(int)-trans_gray.astype(int)).astype(np.uint8)\n",
    "        prev = get_non_zero_points(nice_pic)\n",
    "        \n",
    "        nextp, status, error = cv2.calcOpticalFlowPyrLK(trans_prev_gray, trans_gray, prev, None, **lk_params)\n",
    "        \n",
    "        good_old = prev[status == 1].astype(int)\n",
    "        good_new = nextp[status == 1].astype(int)\n",
    "\n",
    "        new_points = []\n",
    "        old_points = []\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            mask = cv2.line(mask, (a, b), (c, d), color, 2)\n",
    "            frame = cv2.circle(frame, (a, b), 3, color, -1)\n",
    "            new_points.append(np.array([a, b]))\n",
    "            old_points.append(np.array([c, d]))\n",
    "        trajectories.continue_trajectories(new_points, old_points, idx)\n",
    "\n",
    "        output = cv2.add(frame, mask)\n",
    "        prev_gray = gray.copy()\n",
    "#         prev = good_new.reshape(-1, 1, 2)\n",
    "        \n",
    "        if create_vid: \n",
    "            cv2.imwrite(f'tmp/frame_{str(idx).zfill(4)}.jpg', output)\n",
    "        else:\n",
    "#             plot_one_image(output)\n",
    "            pass\n",
    "    cap.release()\n",
    "#     draw_trajectories(list_frames, trajectories)\n",
    "    return trajectories, list_frames\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "bf1bc522",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clip_37.mov\n",
      "1800.0 1920.0 1080.0 29.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de7423daf3845d9a786ccca0d93d4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1799 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmp len 1 1\n",
      "cmp len 4735 3858\n",
      "cmp len 5943 4317\n",
      "cmp len 7008 4600\n",
      "cmp len 7435 4567\n",
      "cmp len 7759 4644\n",
      "cmp len 8021 4144\n",
      "cmp len 8097 3003\n",
      "cmp len 8120 3562\n",
      "cmp len 8257 3844\n",
      "cmp len 8390 6336\n",
      "cmp len 10201 3660\n",
      "cmp len 10342 3786\n",
      "cmp len 10432 3706\n",
      "cmp len 10544 4285\n",
      "cmp len 10693 4111\n",
      "cmp len 10745 4553\n",
      "cmp len 10855 5196\n",
      "cmp len 11152 5104\n",
      "cmp len 11307 5002\n",
      "cmp len 11440 5488\n",
      "cmp len 11630 4190\n",
      "cmp len 11682 7974\n",
      "cmp len 12632 6136\n",
      "cmp len 12892 5647\n",
      "cmp len 12994 5313\n",
      "cmp len 13145 5140\n",
      "cmp len 13272 6110\n",
      "cmp len 13441 6090\n",
      "cmp len 13515 5597\n"
     ]
    }
   ],
   "source": [
    "cap = get_video(2)\n",
    "trajectories, list_frames = get_trajectory(cap, 30, True)\n",
    "# create_video('tmp', size=np.array((1920.0 , 1080.0)), vido_format='mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "537a4052",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1903323218.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [450], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    print('count normal trajectories', len(tr _dist))\u001b[0m\n\u001b[1;37m                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "tr_lens = trajectories.get_trajectories_len()\n",
    "tr_dist = trajectories.get_trajectories_dist()\n",
    "print('count trajectories', len(tr_lens))\n",
    "tr_dist = tr_dist[tr_lens > 5]\n",
    "print('count normal trajectories', len(tr_dist))\n",
    "print('dists', np.unique(tr_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "647bbf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(tr_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21200252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0bbd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c02072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b036e1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c439a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "ff9a673b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427243544b414386a2102f91efe5add8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_video('tmp', size=np.array((1920.0 , 1080.0)), vido_format='mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "281fbe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp.mp4\n",
      "201.0 1920.0 1080.0 20.0\n"
     ]
    }
   ],
   "source": [
    "show_video(sleep=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "583b0d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_details(cap, do_print=True):\n",
    "    cnt = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    if do_print:\n",
    "        print(cnt, w, h, fps)\n",
    "    return cnt, w, h, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be76a7f8-b6e7-4fcf-9799-c4a0b0d9f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video(num, path='./Videos/Videos/'):\n",
    "    \"\"\"\n",
    "    Функция достающая видео\n",
    "    num - номер видео (если num == -1, то достаются все видео)\n",
    "    \n",
    "    \"\"\"\n",
    "    all_names = os.listdir(path)\n",
    "    names = []\n",
    "    for name in all_names:\n",
    "        if name.endswith(\".mov\") or name.endswith(\".mp4\"):\n",
    "            names.append(name)\n",
    "    if num >= 0:\n",
    "        print(name)\n",
    "        name_vid = names[num]\n",
    "        return cv2.VideoCapture(path+name_vid)\n",
    "    \n",
    "    videos = []\n",
    "    for name_vid in names:\n",
    "        videos.append(cv2.VideoCapture(path+name_vid))\n",
    "    return videos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ef74c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clip_1.mov', 'Clip_10.mov', 'Clip_11.mov', 'Clip_2.mov', 'Clip_3.mov', 'Clip_37.mov', 'Clip_4.mov', 'Clip_5.mov', 'Clip_6.mov', 'Clip_7.mov', 'Clip_8.mov', 'Clip_9.mov']\n",
      "./Videos/Videos/Clip_1.mov\n",
      "309.0 1920.0 1080.0 29.97\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mshow_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Videos/Videos/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [4], line 11\u001b[0m, in \u001b[0;36mshow_video\u001b[1;34m(num, path, sleep)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sleep \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse optical flow\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "show_video(0, './Videos/Videos/', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d6a5be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tmp.mp4']\n",
      "./tmp/tmp.mp4\n",
      "308.0 1920.0 1080.0 20.0\n"
     ]
    }
   ],
   "source": [
    "show_video(sleep=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4c50162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9609830a510c4c098de131866e0232d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/308 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tmp.mov']\n",
      "./tmp/tmp.mov\n",
      "308.0 1920.0 1080.0 20.0\n"
     ]
    }
   ],
   "source": [
    "create_video('tmp', size=np.array((1920.0 , 1080.0)), vido_format='mov')\n",
    "show_video(sleep=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "3f705c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309.0 1920.0 1080.0 29.97\n",
      "1800.0 1920.0 1080.0 29.97\n",
      "1800.0 1920.0 1080.0 29.97\n",
      "1800.0 1920.0 1080.0 29.97\n",
      "1800.0 1920.0 1080.0 29.97\n",
      "1800.0 1920.0 1080.0 29.97\n",
      "1800.0 1920.0 1080.0 29.97\n",
      "1800.0 1920.0 1080.0 29.97\n",
      "1800.0 1920.0 1080.0 29.97\n",
      "1800.0 1920.0 1080.0 29.97\n",
      "1800.0 1920.0 1080.0 29.97\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    cap = get_video(i)\n",
    "    get_video_details(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "05e5fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 4, 7, 8, 9}\n",
      "{10, 3, 5, 6}\n"
     ]
    }
   ],
   "source": [
    "a = range(11)\n",
    "b = [3,5,6,10]\n",
    "print(set(a) ^ set(b))\n",
    "print(set(a) & set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f3595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
